import { NextRequest, NextResponse } from 'next/server';

export async function POST(request: NextRequest) {
    try {
        console.log('ğŸ¤ Local Speech API called');

        const formData = await request.formData();
        const audioFile = formData.get('audio') as File;

        if (!audioFile) {
            return NextResponse.json(
                { error: 'ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª' },
                { status: 400 }
            );
        }

        console.log('ğŸ“ Audio file received:', {
            name: audioFile.name,
            size: audioFile.size,
            type: audioFile.type
        });

        // For now, we'll implement a simple fallback that returns a placeholder
        // In a real implementation, you could use:
        // 1. A local Whisper model
        // 2. Google Speech-to-Text API
        // 3. Azure Speech Services
        // 4. Other speech recognition services

        // Simulate processing time
        await new Promise(resolve => setTimeout(resolve, 1000));

        // For demo purposes, return a more realistic text based on common commands
        // In production, you'd implement actual speech recognition

        // Try to guess based on audio file size and common patterns
        let predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ø®ÙˆØ¯Ù…'; // Default to personal report

        // Simple heuristic based on file size (larger files might be longer commands)
        if (audioFile.size > 100000) {
            predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ø± Ø§Ø­Ù…Ø¯';
        } else if (audioFile.size > 80000) {
            predictedText = 'ØªØ­Ù„ÛŒÙ„ ÙØ±ÙˆØ´';
        } else if (audioFile.size > 60000) {
            predictedText = 'Ú¯Ø²Ø§Ø±Ø´ Ø®ÙˆØ¯Ù…';
        }

        console.log('ğŸ”® Predicted text based on heuristics:', predictedText);

        console.log('âœ… Local speech processing completed (demo mode)');

        return NextResponse.json({
            success: true,
            text: predictedText,
            provider: 'local-demo',
            language: 'fa',
            confidence: 0.6, // Lower confidence for demo
            note: 'Ø§ÛŒÙ† ÛŒÚ© Ù†Ø³Ø®Ù‡ Ø¢Ø²Ù…Ø§ÛŒØ´ÛŒ Ø§Ø³Øª. Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ ÙˆØ§Ù‚Ø¹ÛŒØŒ Ø³Ø±ÙˆÛŒØ³ ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± Ø¨Ø§ÛŒØ¯ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ø´ÙˆØ¯.'
        });

    } catch (error) {
        console.error('âŒ Error in Local Speech API:', error);

        return NextResponse.json(
            {
                error: 'Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø­Ù„ÛŒ ØµØ¯Ø§',
                details: error instanceof Error ? error.message : 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ'
            },
            { status: 500 }
        );
    }
}